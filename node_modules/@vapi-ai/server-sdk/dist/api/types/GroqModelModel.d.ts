/**
 * This file was auto-generated by Fern from our API Definition.
 */
/**
 * This is the name of the model. Ex. cognitivecomputations/dolphin-mixtral-8x7b
 */
export type GroqModelModel = "deepseek-r1-distill-llama-70b" | "llama-3.3-70b-versatile" | "llama-3.1-405b-reasoning" | "llama-3.1-8b-instant" | "llama3-8b-8192" | "llama3-70b-8192" | "gemma2-9b-it" | "meta-llama/llama-4-maverick-17b-128e-instruct" | "meta-llama/llama-4-scout-17b-16e-instruct" | "mistral-saba-24b" | "compound-beta" | "compound-beta-mini";
export declare const GroqModelModel: {
    readonly DeepseekR1DistillLlama70B: "deepseek-r1-distill-llama-70b";
    readonly Llama3370BVersatile: "llama-3.3-70b-versatile";
    readonly Llama31405BReasoning: "llama-3.1-405b-reasoning";
    readonly Llama318BInstant: "llama-3.1-8b-instant";
    readonly Llama38B8192: "llama3-8b-8192";
    readonly Llama370B8192: "llama3-70b-8192";
    readonly Gemma29BIt: "gemma2-9b-it";
    readonly MetaLlamaLlama4Maverick17B128EInstruct: "meta-llama/llama-4-maverick-17b-128e-instruct";
    readonly MetaLlamaLlama4Scout17B16EInstruct: "meta-llama/llama-4-scout-17b-16e-instruct";
    readonly MistralSaba24B: "mistral-saba-24b";
    readonly CompoundBeta: "compound-beta";
    readonly CompoundBetaMini: "compound-beta-mini";
};
